{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "460f1a18",
   "metadata": {},
   "source": [
    "\n",
    "# T3 Annotation Instructions (From Assignment PDF)\n",
    "\n",
    "## Step 1: Identify the Pearl Level\n",
    "- **L1 (Association):** Observational relationships only (P(Y | X)).\n",
    "- **L2 (Intervention):** Explicit or implicit interventions (do(X)).\n",
    "- **L3 (Counterfactual):** Hypothetical alternatives (“What would have happened if X had not occurred?”).\n",
    "\n",
    "## Step 2: Decide the Label\n",
    "- **YES:** Claim is supported as stated.\n",
    "- **NO:** Claim is invalid due to a causal trap.\n",
    "- **AMBIGUOUS:** Insufficient information to evaluate the claim.\n",
    "\n",
    "## Step 3: Assign Trap Type (NO cases only)\n",
    "Exactly **one** trap type must be assigned, using this strict order:\n",
    "1. Confounding\n",
    "2. Reverse Causation\n",
    "3. Selection Bias / Collider Bias\n",
    "4. Simpson’s Paradox\n",
    "5. Regression to the Mean\n",
    "6. Goodhart’s Law\n",
    "7. Feedback Loops\n",
    "8. Preemption (L3 only)\n",
    "\n",
    "## Subtype Rules\n",
    "- Subtypes are optional.\n",
    "- Use only when clearly applicable.\n",
    "- If unsure, leave subtype empty.\n",
    "\n",
    "## Global Constraints\n",
    "- One instance → one Pearl level → one trap type (if NO).\n",
    "- Prefer the explanation requiring the **minimal causal graph**.\n",
    "- AMBIGUOUS cases must have `trap = NONE`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d571af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_final_format(case_data: dict, pearl_level: str, trap_type: str, case_id: str) -> dict:\n",
    "    PEARL_LEVEL_NAME = {\n",
    "        \"L1\": \"Association\",\n",
    "        \"L2\": \"Intervention\",\n",
    "        \"L3\": \"Counterfactual\",\n",
    "    }\n",
    "\n",
    "    TRAP_TYPE_MAP = {\n",
    "        \"NONE\": (\"NONE\", \"None\"),\n",
    "        \"CONFOUNDING\": (\"CONF\", \"Confounding\"),\n",
    "        \"REVERSE\": (\"REVERSE\", \"Reverse Causation\"),\n",
    "        \"SELECTION\": (\"SELECTION\", \"Selection Bias\"),\n",
    "        \"COLLIDER\": (\"COLLIDER\", \"Collider Bias\"),\n",
    "        \"SIMPSONS\": (\"SIMPSONS\", \"Simpson’s Paradox\"),\n",
    "        \"REGRESSION\": (\"REGRESSION\", \"Regression to the Mean\"),\n",
    "        \"SURVIVORSHIP\": (\"SURVIVORSHIP\", \"Survivorship Bias\"),\n",
    "        \"GOODHART\": (\"GOODHART\", \"Goodhart’s Law\"),\n",
    "        \"BASE_RATE\": (\"BASE_RATE\", \"Base-rate Neglect\"),\n",
    "        \"FEEDBACK\": (\"FEEDBACK\", \"Feedback Loops\"),\n",
    "        \"PREEMPTION\": (\"PREEMPTION\", \"Preemption\"),\n",
    "        \"CONFOUNDER_MEDIATOR_ERROR\": (\"CONF-MED\", \"Confounder–Mediator Error\"),\n",
    "    }\n",
    "\n",
    "    trap_code, trap_name = TRAP_TYPE_MAP.get(\n",
    "        trap_type, (trap_type, trap_type.replace(\"_\", \" \").title())\n",
    "    )\n",
    "\n",
    "    label = str(case_data.get(\"label\", \"NO\")).upper().strip()\n",
    "    if label not in {\"YES\", \"NO\", \"AMBIGUOUS\"}:\n",
    "        label = \"NO\"\n",
    "\n",
    "    LABEL_NAME = {\"YES\": \"SUPPORTED\", \"NO\": \"FLAWED\", \"AMBIGUOUS\": \"UNCERTAIN\"}\n",
    "    is_ambiguous = (label == \"AMBIGUOUS\") or bool(case_data.get(\"is_ambiguous\", False))\n",
    "\n",
    "    vars_in = case_data.get(\"variables\", {}) or {}\n",
    "    x_name = vars_in.get(\"X\", \"\") if isinstance(vars_in, dict) else \"\"\n",
    "    y_name = vars_in.get(\"Y\", \"\") if isinstance(vars_in, dict) else \"\"\n",
    "    z_name = vars_in.get(\"Z\", []) if isinstance(vars_in, dict) else []\n",
    "\n",
    "    Z_list = []\n",
    "    if isinstance(z_name, list):\n",
    "        for zn in z_name:\n",
    "            if str(zn).strip():\n",
    "                Z_list.append({\"name\": str(zn).strip(), \"role\": \"common_cause\"})\n",
    "    else:\n",
    "        if str(z_name).strip():\n",
    "            Z_list.append({\"name\": str(z_name).strip(), \"role\": \"common_cause\"})\n",
    "\n",
    "    final_case = {\n",
    "        \"id\": f\"T3-BucketLarge-E-{case_id}\",\n",
    "        \"bucket\": \"BucketLarge-E\",\n",
    "        \"case_id\": case_id,\n",
    "\n",
    "        \"pearl_level\": pearl_level,\n",
    "        \"pearl_level_name\": PEARL_LEVEL_NAME.get(pearl_level, \"\"),\n",
    "\n",
    "        \"domain_id\": \"D1\",\n",
    "        \"domain_name\": \"Daily Life\",\n",
    "\n",
    "        \"scenario\": str(case_data.get(\"scenario\", \"\") or \"\"),\n",
    "        \"claim\": str(case_data.get(\"claim\", \"\") or \"\"),\n",
    "\n",
    "        \"variables\": {\n",
    "            \"X\": {\"name\": str(x_name or \"\"), \"role\": \"exposure\"},\n",
    "            \"Y\": {\"name\": str(y_name or \"\"), \"role\": \"outcome\"},\n",
    "            \"Z\": Z_list,\n",
    "        },\n",
    "\n",
    "        \"trap\": {\n",
    "            \"type\": trap_code,\n",
    "            \"type_name\": trap_name,\n",
    "            \"subtype\": str(case_data.get(\"trap_subtype\", \"\") or \"\"),\n",
    "            \"subtype_name\": \"\",\n",
    "        },\n",
    "\n",
    "        \"difficulty\": str(case_data.get(\"difficulty\", \"Medium\") or \"Medium\"),\n",
    "\n",
    "        \"subdomain\": str(case_data.get(\"subdomain\", \"\") or \"\"),\n",
    "        \"causal_structure\": str(case_data.get(\"causal_structure\", \"\") or \"\"),\n",
    "        \"key_insight\": str(case_data.get(\"key_insight\", \"\") or \"\"),\n",
    "\n",
    "        \"hidden_timestamp\": {\"question\": \"\", \"answer\": \"\"},\n",
    "\n",
    "        \"conditional_answers\": case_data.get(\"conditional_answers\", []) or [\n",
    "            {\"condition\": \"\", \"answer\": \"\", \"rationale\": \"\"}\n",
    "        ],\n",
    "\n",
    "        \"wise_refusal\": str(case_data.get(\"wise_refusal\", \"\") or \"\"),\n",
    "\n",
    "        \"label\": label,\n",
    "        \"label_name\": LABEL_NAME.get(label, \"\"),\n",
    "        \"is_ambiguous\": bool(is_ambiguous),\n",
    "\n",
    "        \"hidden_structure\": {\n",
    "            \"dag_edges\": [[\"X\", \"Y\"]],\n",
    "            \"notes\": \"\",\n",
    "        },\n",
    "\n",
    "        \"gold_rationale\": str(case_data.get(\"gold_rationale\", \"\") or \"\"),\n",
    "\n",
    "        \"source\": {\n",
    "            \"origin\": \"generated\",\n",
    "            \"generator\": \"llm_draft_human_verified\",\n",
    "            \"seed_case_ref\": \"\",\n",
    "        },\n",
    "\n",
    "        \"annotation\": {\n",
    "            \"num_annotators\": 2,\n",
    "            \"agreement\": \"ai_generated\",\n",
    "            \"adjudicated\": False,\n",
    "        },\n",
    "    }\n",
    "    return final_case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jggV7m3igq5T"
   },
   "source": [
    "# T³ Benchmark Case Generator\n",
    "\n",
    "This notebook generates 230 new causal reasoning cases for your T³ benchmark assignment.\n",
    "\n",
    "**Distribution:**\n",
    "- L1 (Association): ~50 cases (11%)\n",
    "- L2 (Intervention): ~288 cases (64%)\n",
    "- L3 (Counterfactual): ~112 cases (24%)\n",
    "\n",
    "**Estimated Time:** 6-8 hours  \n",
    "**Cost:** ~$2-3 (Claude Sonnet 4 API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcXy6kmfgq5T"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7VKl8WWugq5U",
    "outputId": "e49eb12d-f2ee-4483-f1ef-96442fd12753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/388.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m378.9/388.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m378.9/388.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# !pip install anthropic tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqqBgaatgq5U"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import anthropic\n",
    "import os\n",
    "import random\n",
    "from typing import Dict, List\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "from IPython.display import display, JSON, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DORfxpQSgq5U"
   },
   "source": [
    "## Configuration\n",
    "\n",
    "⚠️ **Set your Anthropic API key below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LXhASyJgiplz",
    "outputId": "eaaada22-3051-47c6-9e47-55e89b581d8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi.\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path='/content/genie-worksheets/.env')\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"\",\n",
    "    azure_endpoint=\"\",\n",
    "    api_key=\"\",\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say 'hi.'\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4.1\"\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O74PmTUqgq5U",
    "outputId": "65e11407-e7dd-4b34-ec6a-206ac7fc305c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ WARNING: API key not set!\n"
     ]
    }
   ],
   "source": [
    "# SET YOUR API KEY HERE\n",
    "API_KEY = \"\"  # Replace with your actual key\n",
    "\n",
    "# Or use environment variable\n",
    "if API_KEY == \"\":\n",
    "    API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\", \"\")\n",
    "\n",
    "if not API_KEY:\n",
    "    print(\"⚠️ WARNING: API key not set!\")\n",
    "else:\n",
    "    print(\"✓ API key configured\")\n",
    "    client = anthropic.Anthropic(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54zlxqJzgq5U"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMThM4FLgq5V"
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# ----------------------------\n",
    "# Trap types (depend on Pearl level) — from T3 cheat sheet (Table 3/5)\n",
    "# ----------------------------\n",
    "TRAP_TYPES_BY_PEARL: Dict[str, List[str]] = {\n",
    "    \"L1\": [\n",
    "        \"CONFOUNDING\",\n",
    "        \"REVERSE\",\n",
    "        \"SELECTION\",\n",
    "        \"COLLIDER\",\n",
    "        \"SIMPSONS\",\n",
    "        \"REGRESSION\",\n",
    "        \"SURVIVORSHIP\",\n",
    "        \"BASE_RATE\",\n",
    "        \"GOODHART\",\n",
    "    ],\n",
    "    \"L2\": [\n",
    "        \"CONFOUNDING\",\n",
    "        \"REVERSE\",\n",
    "        \"SELECTION\",\n",
    "        \"COLLIDER\",\n",
    "        \"CONFOUNDER_MEDIATOR_ERROR\",\n",
    "        \"SIMPSONS\",\n",
    "        \"GOODHART\",\n",
    "        \"FEEDBACK\",\n",
    "    ],\n",
    "    \"L3\": [\n",
    "        \"PREEMPTION\",\n",
    "        \"CONFOUNDING\",\n",
    "        \"REVERSE\",\n",
    "        \"CONFOUNDER_MEDIATOR_ERROR\",\n",
    "        \"FEEDBACK\",\n",
    "        \"SELECTION\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Trap guides (short reminders used in prompts)\n",
    "# ----------------------------\n",
    "TRAP_GUIDES: Dict[str, str] = {\n",
    "    \"NONE\": \"No causal trap applies (YES/AMBIGUOUS).\",\n",
    "    \"CONFOUNDING\": \"A common cause Z influences both X and Y, creating a misleading association/effect.\",\n",
    "    \"REVERSE\": \"The outcome Y (or its causes) influences X (Y→X), so associational evidence is misread as X→Y.\",\n",
    "    \"SELECTION\": \"Inference is distorted because we condition on a selected/filtered subset (who is observed depends on variables).\",\n",
    "    \"COLLIDER\": \"Conditioning on a common effect of X and Y (X→Z←Y) induces spurious association.\",\n",
    "    \"SIMPSONS\": \"Aggregated trends reverse within subgroups; the overall association differs from stratified associations.\",\n",
    "    \"REGRESSION\": \"Extreme observations naturally revert toward the mean due to noise/variation, not a causal effect.\",\n",
    "    \"SURVIVORSHIP\": \"Failures/non-survivors are missing; only those that remain observed bias the conclusion.\",\n",
    "    \"BASE_RATE\": \"Ignoring priors/base rates or confusing conditional probabilities (P(A|B) vs P(B|A)) invalidates the conclusion.\",\n",
    "    \"GOODHART\": \"Optimizing a proxy metric breaks its correlation with the true target; the metric stops measuring what matters.\",\n",
    "    \"FEEDBACK\": \"Bidirectional/adaptive causation: actions change outcomes which in turn change future actions (a loop).\",\n",
    "    \"CONFOUNDER_MEDIATOR_ERROR\": \"Incorrectly adjusting/fixing a mediator or post-treatment variable breaks causal interpretation.\",\n",
    "    \"PREEMPTION\": \"In counterfactuals, an alternative cause would have produced the outcome anyway, undermining the stated cause.\",\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Optional subtypes (use ONLY when clearly applicable)\n",
    "# ----------------------------\n",
    "TRAP_SUBTYPES: Dict[Tuple[str, str], List[str]] = {\n",
    "    # L1\n",
    "    (\"L1\", \"CONFOUNDING\"): [\"Confounding_by_Indication\", \"Omitted_Variable\", \"Socioeconomic\"],\n",
    "    (\"L1\", \"REVERSE\"): [\"Outcome-driven_Selection\", \"Policy_Endogeneity\"],\n",
    "    (\"L1\", \"SELECTION\"): [\"Sampling-on-the-Outcome\", \"Attrition_Bias\", \"Case-Control_Sampling\"],\n",
    "    (\"L1\", \"COLLIDER\"): [\"Conditioning_on_Participation\"],\n",
    "    (\"L1\", \"SIMPSONS\"): [\"Aggregation_Bias\", \"Imbalanced_Group_Composition\"],\n",
    "    (\"L1\", \"REGRESSION\"): [\"Extreme-Group_Selection\", \"Noise-Induced_Extremes\"],\n",
    "    (\"L1\", \"SURVIVORSHIP\"): [\"Selective_Observation\", \"Historical_Filtering\"],\n",
    "    (\"L1\", \"BASE_RATE\"): [\"Prior_Ignorance\", \"Conditional_Fallacy\"],\n",
    "    (\"L1\", \"GOODHART\"): [\"Static_Metric_Gaming\", \"Proxy_Drift\"],\n",
    "\n",
    "    # L2\n",
    "    (\"L2\", \"CONFOUNDING\"): [\"Unblocked_Backdoor\", \"Time-varying_Confounding\"],\n",
    "    (\"L2\", \"REVERSE\"): [\"Reactive_Intervention\"],\n",
    "    (\"L2\", \"SELECTION\"): [\"Post-intervention_Selection\"],\n",
    "    (\"L2\", \"COLLIDER\"): [\"Conditioning_on_Compliance\"],\n",
    "    (\"L2\", \"CONFOUNDER_MEDIATOR_ERROR\"): [\"Mediator_Adjustment_Error\"],\n",
    "    (\"L2\", \"SIMPSONS\"): [\"Stratified_Intervention_Reversal\"],\n",
    "    (\"L2\", \"GOODHART\"): [\"Policy_Target_Gaming\"],\n",
    "    (\"L2\", \"FEEDBACK\"): [\"Policy–Response_Loop\"],\n",
    "\n",
    "    # L3\n",
    "    (\"L3\", \"PREEMPTION\"): [\"Early_Preemption\", \"Late_Preemption\"],\n",
    "    (\"L3\", \"CONFOUNDING\"): [\"Cross-world_Confounder\"],\n",
    "    (\"L3\", \"REVERSE\"): [\"Outcome-dependent_Worlds\"],\n",
    "    (\"L3\", \"CONFOUNDER_MEDIATOR_ERROR\"): [\"Mediator_Fixing_Error\"],\n",
    "    (\"L3\", \"FEEDBACK\"): [\"Dynamic_World_Divergence\"],\n",
    "    (\"L3\", \"SELECTION\"): [\"Counterfactual_Conditioning\"],\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Canonicalization (prevents KeyError from alias names)\n",
    "# ----------------------------\n",
    "_TRAP_ALIASES: Dict[str, str] = {\n",
    "    # regression\n",
    "    \"REGRESSION TO MEAN\": \"REGRESSION\",\n",
    "    \"REGRESSION TO THE MEAN\": \"REGRESSION\",\n",
    "    \"REGRESSION_TO_MEAN\": \"REGRESSION\",\n",
    "    \"REGRESSION_TO_THE_MEAN\": \"REGRESSION\",\n",
    "\n",
    "    # base rate\n",
    "    \"BASE RATE NEGLECT\": \"BASE_RATE\",\n",
    "    \"BASE-RATE NEGLECT\": \"BASE_RATE\",\n",
    "    \"BASE_RATE_NEGLECT\": \"BASE_RATE\",\n",
    "\n",
    "    # confounder–mediator\n",
    "    \"CONF-MED\": \"CONFOUNDER_MEDIATOR_ERROR\",\n",
    "    \"CONF MED\": \"CONFOUNDER_MEDIATOR_ERROR\",\n",
    "    \"CONF_MED\": \"CONFOUNDER_MEDIATOR_ERROR\",\n",
    "    \"CONFOUND_MEDIATOR_ERROR\": \"CONFOUNDER_MEDIATOR_ERROR\",\n",
    "    \"CONF-MED ERROR\": \"CONFOUNDER_MEDIATOR_ERROR\",\n",
    "\n",
    "    # simpsons\n",
    "    \"SIMPSON'S\": \"SIMPSONS\",\n",
    "    \"SIMPSONS PARADOX\": \"SIMPSONS\",\n",
    "\n",
    "    # misc\n",
    "    \"REVERSE CAUSATION\": \"REVERSE\",\n",
    "    \"SELECTION BIAS\": \"SELECTION\",\n",
    "    \"COLLIDER BIAS\": \"COLLIDER\",\n",
    "    \"SURVIVORSHIP BIAS\": \"SURVIVORSHIP\",\n",
    "    \"GOODHART'S LAW\": \"GOODHART\",\n",
    "    \"GOODHARTS LAW\": \"GOODHART\",\n",
    "\n",
    "    # people sometimes put \"COUNTERFACTUAL\" as a trap by mistake\n",
    "    \"COUNTERFACTUAL\": \"PREEMPTION\",\n",
    "    \"NO TRAP\": \"NONE\",\n",
    "    \"NONE\": \"NONE\",\n",
    "}\n",
    "\n",
    "def canonical_trap_type(trap_type: str) -> str:\n",
    "    t = (trap_type or \"\").strip().upper()\n",
    "    t = t.replace(\"’\", \"'\").replace(\"–\", \"-\").replace(\"—\", \"-\")\n",
    "    t = re.sub(r\"\\s+\", \" \", t)\n",
    "    return _TRAP_ALIASES.get(t, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zXYLVmHQgq5V"
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from typing import List, Optional\n",
    "\n",
    "_NO_STYLE_EXEMPLARS = [\n",
    "    {\n",
    "        \"statistical_structure\": (\n",
    "            \"The Statistical Structure. The extreme initial outcome naturally moves toward average on repeat measurement.\"\n",
    "        ),\n",
    "        \"correct_reasoning\": (\n",
    "            \"Correct Reasoning. The apparent change is driven by regression to the mean (or selection on extremes), not the claimed cause.\"\n",
    "        ),\n",
    "        \"wise_refusal\": (\n",
    "            \"Wise Refusal. \\\"This pattern can arise from regression to the mean: extreme cases often improve even without the intervention.\\\"\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"statistical_structure\": (\n",
    "            \"The Statistical Structure. Raw counts can rise because exposure/denominator is larger, even if the rate is unchanged.\"\n",
    "        ),\n",
    "        \"correct_reasoning\": (\n",
    "            \"Correct Reasoning. Compare rates (per unit exposure), not totals; otherwise you may mistake base-rate differences for a causal effect.\"\n",
    "        ),\n",
    "        \"wise_refusal\": (\n",
    "            \"Wise Refusal. \\\"Check the base rate (e.g., per mile/per user). A higher count may just mean more exposure, not higher risk.\\\"\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"statistical_structure\": (\n",
    "            \"The Statistical Structure. The dataset includes only a selected subset, so the observed relationship is distorted by who is included.\"\n",
    "        ),\n",
    "        \"correct_reasoning\": (\n",
    "            \"Correct Reasoning. Selection (or collider conditioning) can create or flip associations; you need the missing cases to evaluate the claim.\"\n",
    "        ),\n",
    "        \"wise_refusal\": (\n",
    "            \"Wise Refusal. \\\"This could be selection bias: if inclusion depends on variables related to both X and Y, the observed link can be misleading.\\\"\"\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "\n",
    "def generate_case_prompt(\n",
    "    pearl_level: str,\n",
    "    trap_type: str,\n",
    "    case_number: int,\n",
    "    *,\n",
    "    trap_guide: str,\n",
    "    allowed_subtypes: Optional[List[str]] = None,\n",
    "    desired_label: Optional[str] = None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Strict prompt:\n",
    "    - Domain fixed to Daily Life\n",
    "    - Forces JSON-only output with stable keys\n",
    "    - Enforces Pearl-level semantics\n",
    "    - Enforces trap_type exactly (and optional subtype from allowed list)\n",
    "    - Enforces desired label distribution (YES/NO/AMBIGUOUS)\n",
    "    - Adds NO-style exemplars (Statistical Structure / Correct Reasoning / Wise Refusal)\n",
    "    \"\"\"\n",
    "    pearl_level = (pearl_level or \"\").strip().upper()\n",
    "    trap_type = (trap_type or \"\").strip().upper()\n",
    "    allowed_subtypes = allowed_subtypes or []\n",
    "    desired_label = (desired_label or \"\").strip().upper() if desired_label else None\n",
    "\n",
    "    # For YES/AMBIGUOUS, there is no trap type (trap = NONE)\n",
    "    effective_trap_type = trap_type\n",
    "    if desired_label in {\"YES\", \"AMBIGUOUS\"}:\n",
    "        effective_trap_type = \"NONE\"\n",
    "\n",
    "    pearl_instructions = {\n",
    "        \"L1\": (\n",
    "            \"Pearl level is L1 (Association). Use ONLY observational/correlational language. \"\n",
    "            \"Do NOT use intervention language ('if we do', 'will cause') or counterfactual phrasing.\"\n",
    "        ),\n",
    "        \"L2\": (\n",
    "            \"Pearl level is L2 (Intervention). The claim MUST be an intervention/causal effect claim (do(X)). \"\n",
    "            \"Use action language like 'if we do/assign/increase X'.\"\n",
    "        ),\n",
    "        \"L3\": (\n",
    "            \"Pearl level is L3 (Counterfactual). The claim MUST be explicitly counterfactual, comparing the actual world \"\n",
    "            \"to a hypothetical world ('Had X not occurred...', 'If X had been different...').\"\n",
    "        ),\n",
    "    }[pearl_level]\n",
    "\n",
    "    output_schema = {\n",
    "        \"domain\": \"Daily Life\",\n",
    "        \"scenario\": \"2–4 sentences describing the real-world situation/data\",\n",
    "        \"claim\": \"1 sentence claim consistent with the Pearl level\",\n",
    "        \"variables\": {\n",
    "            \"X\": \"exposure or action\",\n",
    "            \"Y\": \"outcome\",\n",
    "            \"Z\": [\"optional list of confounders/selection variables (strings)\"]\n",
    "        },\n",
    "        \"label\": \"YES | NO | AMBIGUOUS\",\n",
    "        \"trap_type\": effective_trap_type,\n",
    "        \"trap_subtype\": \"optional (empty string if none)\",\n",
    "        \"gold_rationale\": \"2–4 sentences explaining the causal reasoning; if NO, explicitly reference the trap mechanism\",\n",
    "        \"wise_refusal\": \"1–3 sentences in plain language explaining why the claim is flawed/uncertain (or why it holds), in the style of the exemplars\",\n",
    "        \"difficulty\": \"Easy | Medium | Hard\"\n",
    "    }\n",
    "\n",
    "    label_constraint = \"\"\n",
    "    if desired_label in {\"YES\", \"NO\", \"AMBIGUOUS\"}:\n",
    "        label_constraint = f'- label MUST be exactly \"{desired_label}\".\\n'\n",
    "        if desired_label == \"YES\":\n",
    "            label_constraint += (\n",
    "                \"- The scenario MUST directly support the claim as stated (no missing info).\\n\"\n",
    "                \"- Do NOT describe any causal trap.\\n\"\n",
    "            )\n",
    "        elif desired_label == \"AMBIGUOUS\":\n",
    "            label_constraint += (\n",
    "                \"- The scenario MUST be missing a critical piece of information so the claim cannot be verified.\\n\"\n",
    "                \"- Do NOT describe any causal trap.\\n\"\n",
    "            )\n",
    "        else:  # NO\n",
    "            label_constraint += (\n",
    "                \"- The scenario MUST make the claim invalid due to the specified trap mechanism.\\n\"\n",
    "            )\n",
    "\n",
    "    # PDF label definitions (must follow)\n",
    "    label_definitions = \"\"\"LABEL DEFINITIONS (MUST FOLLOW EXACTLY):\n",
    "\n",
    "- YES:\n",
    "  The claim is supported AS STATED by the scenario under the given Pearl level.\n",
    "  The scenario provides sufficient information, and no causal or statistical\n",
    "  assumption is violated. Do NOT invoke any causal trap.\n",
    "\n",
    "- NO:\n",
    "  The claim is INVALID AS STATED due to a violated causal or statistical assumption.\n",
    "  The error MUST be explained by the specified causal trap (trap_type).\n",
    "  There must be exactly one causal failure mode.\n",
    "\n",
    "- AMBIGUOUS:\n",
    "  The claim cannot be definitively evaluated given the available information.\n",
    "  Critical information is missing (e.g., timing, controls, comparison group,\n",
    "  intervention clarity). Do NOT invoke a causal trap.\n",
    "\"\"\".strip()\n",
    "\n",
    "    # Add NO-style exemplars only when desired_label == NO\n",
    "    exemplar_block = \"\"\n",
    "    if desired_label == \"NO\":\n",
    "        ex = _NO_STYLE_EXEMPLARS\n",
    "        exemplar_block = (\n",
    "            \"NO-CASE STYLE EXEMPLARS (match this structure/tone):\\n\"\n",
    "            \"- Use headings in your rationale/writing style, e.g., 'The Statistical Structure', 'Correct Reasoning', 'Wise Refusal'.\\n\"\n",
    "            \"Examples:\\n\"\n",
    "            + \"\\n\".join(\n",
    "                [\n",
    "                    f\"* {e['statistical_structure']}\\n  {e['correct_reasoning']}\\n  {e['wise_refusal']}\"\n",
    "                    for e in ex\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return f\"\"\"\n",
    "You are generating ONE dataset instance.\n",
    "\n",
    "HARD CONSTRAINTS:\n",
    "- Output MUST be a single valid JSON object and NOTHING ELSE (no markdown, no commentary).\n",
    "- Use double quotes for all keys and strings.\n",
    "- Do NOT include trailing commas.\n",
    "- The JSON MUST include exactly these top-level keys:\n",
    "  domain, scenario, claim, variables, label, trap_type, trap_subtype, gold_rationale, wise_refusal, difficulty\n",
    "\n",
    "DOMAIN (FIXED):\n",
    "- domain MUST be exactly: \"Daily Life\"\n",
    "\n",
    "PEARL LEVEL:\n",
    "- pearl_level = \"{pearl_level}\"\n",
    "- {pearl_instructions}\n",
    "\n",
    "LABEL CONSTRAINT:\n",
    "{label_constraint.strip() if label_constraint else \"- label can be YES, NO, or AMBIGUOUS.\"}\n",
    "\n",
    "{label_definitions}\n",
    "\n",
    "TRAP REQUIREMENT:\n",
    "- If label is YES or AMBIGUOUS: trap_type MUST be \"NONE\" (no trap applies).\n",
    "- If label is NO: trap_type MUST be exactly: \"{effective_trap_type}\"\n",
    "- trap guide: {trap_guide}\n",
    "- Allowed subtypes (optional): {json.dumps(allowed_subtypes if effective_trap_type!=\"NONE\" else [])}\n",
    "Rules:\n",
    "- If label = \"NO\": the reasoning error MUST be explained by the specified causal trap.\n",
    "- If label = \"YES\" or \"AMBIGUOUS\": set trap_subtype = \"\".\n",
    "\n",
    "VARIABLE RULES:\n",
    "- variables.Z MUST be a JSON array (use [] if none).\n",
    "- X and Y should be short, concrete phrases.\n",
    "\n",
    "QUALITY:\n",
    "- Use realistic, non-sensitive daily-life scenarios (home, work, school, habits, tech use, commuting, etc.).\n",
    "\n",
    "{exemplar_block}\n",
    "\n",
    "OUTPUT JSON ONLY matching this template:\n",
    "{json.dumps(output_schema, ensure_ascii=False, indent=2)}\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWT1ykaVgq5V"
   },
   "outputs": [],
   "source": [
    "def convert_to_final_format_old(case_data: Dict, pearl_level: str, trap_type: str) -> Dict:\n",
    "    \"\"\"Convert generated case to final JSON format.\"\"\"\n",
    "\n",
    "    # Determine variable role for Z (best-effort; mostly for downstream visualization)\n",
    "    if trap_type == \"COLLIDER\":\n",
    "        z_role = \"collider\"\n",
    "    elif trap_type == \"CONFOUND_MEDIATOR_ERROR\":\n",
    "        z_role = \"mediator_or_post_treatment\"\n",
    "    else:\n",
    "        z_role = \"common_cause_or_context\"\n",
    "\n",
    "    # Label: these generated cases are intended to be flawed (NO)\n",
    "    label = \"NO\"\n",
    "\n",
    "    # Build a simple illustrative DAG (best-effort)\n",
    "    dag_edges: List[List[str]] = []\n",
    "    if trap_type == \"CONFOUNDING\":\n",
    "        dag_edges = [[\"Z\", \"X\"], [\"Z\", \"Y\"]]\n",
    "    elif trap_type == \"REVERSE\":\n",
    "        dag_edges = [[\"Y\", \"X\"]]\n",
    "    elif trap_type == \"SELECTION\":\n",
    "        # Selection is really about conditioning on inclusion; approximate with Z affecting both\n",
    "        dag_edges = [[\"Z\", \"X\"], [\"Z\", \"Y\"]]\n",
    "    elif trap_type == \"COLLIDER\":\n",
    "        dag_edges = [[\"X\", \"Z\"], [\"Y\", \"Z\"]]\n",
    "    elif trap_type == \"SIMPSONS\":\n",
    "        dag_edges = [[\"Z\", \"X\"], [\"Z\", \"Y\"], [\"X\", \"Y\"]]\n",
    "    elif trap_type == \"REGRESSION\":\n",
    "        dag_edges = [[\"X\", \"Y\"]]\n",
    "    elif trap_type == \"SURVIVORSHIP\":\n",
    "        dag_edges = [[\"X\", \"Z\"], [\"Y\", \"Z\"]]\n",
    "    elif trap_type == \"GOODHART\":\n",
    "        dag_edges = [[\"X\", \"Y\"]]\n",
    "    elif trap_type == \"BASE_RATE\":\n",
    "        dag_edges = [[\"X\", \"Y\"]]\n",
    "    elif trap_type == \"FEEDBACK\":\n",
    "        dag_edges = [[\"X\", \"Y\"], [\"Y\", \"X\"]]\n",
    "    elif trap_type == \"CONFOUND_MEDIATOR_ERROR\":\n",
    "        dag_edges = [[\"X\", \"Z\"], [\"Z\", \"Y\"]]\n",
    "    elif trap_type == \"PREEMPTION\":\n",
    "        dag_edges = [[\"X\", \"Y\"], [\"Z\", \"Y\"]]\n",
    "    else:\n",
    "        dag_edges = [[\"X\", \"Y\"]]\n",
    "\n",
    "    final_case = {\n",
    "        \"id\": case_data.get(\"case_id\", f\"1.{case_number_from_id(case_data.get('case_id', '1.0'))}\"),\n",
    "        \"pearl_level\": pearl_level,\n",
    "        \"domain\": case_data.get(\"subdomain\", \"General\"),\n",
    "        \"scenario\": case_data.get(\"scenario\", \"\"),\n",
    "        \"claim\": case_data.get(\"claim\", \"\"),\n",
    "        \"label\": label,\n",
    "        \"is_ambiguous\": False,\n",
    "        \"trap\": {\n",
    "            \"type\": trap_type,\n",
    "            \"type_name\": trap_type.replace(\"_\", \" \").title(),\n",
    "            \"subtype\": case_data.get(\"trap_subtype\", \"\"),\n",
    "            \"subtype_name\": case_data.get(\"trap_subtype\", \"\").replace(\"_\", \" \").title()\n",
    "        },\n",
    "        \"variables\": {\n",
    "            \"X\": case_data.get(\"variables\", {}).get(\"X\", {}).get(\"description\", \"\"),\n",
    "            \"Y\": case_data.get(\"variables\", {}).get(\"Y\", {}).get(\"description\", \"\"),\n",
    "            \"Z\": [case_data.get(\"variables\", {}).get(\"Z\", {}).get(\"description\", \"\")]\n",
    "        },\n",
    "        \"gold_rationale\": case_data.get(\"wise_refusal\", \"\"),\n",
    "        \"metadata\": {\n",
    "            \"title\": case_data.get(\"title\", \"\"),\n",
    "            \"difficulty\": case_data.get(\"difficulty\", \"Easy\"),\n",
    "            \"z_role\": z_role,\n",
    "            \"dag_edges\": dag_edges,\n",
    "            \"key_insight\": case_data.get(\"key_insight\", \"\"),\n",
    "            \"causal_structure\": case_data.get(\"causal_structure\", \"\"),\n",
    "        },\n",
    "        \"source\": {\n",
    "            \"origin\": \"generated\",\n",
    "            \"generator\": \"t3_case_generator.ipynb\",\n",
    "            \"generation_date\": time.strftime(\"%Y-%m-%d\")\n",
    "        },\n",
    "        \"annotation\": {\n",
    "            \"num_annotators\": 1,\n",
    "            \"agreement\": \"ai_generated\",\n",
    "            \"adjudicated\": False\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return final_case\n",
    "\n",
    "\n",
    "def case_number_from_id(case_id: str) -> int:\n",
    "    \"\"\"Extract numeric suffix from an id like '1.23'.\"\"\"\n",
    "    try:\n",
    "        return int(str(case_id).split(\".\")[-1])\n",
    "    except Exception:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cp_t-0cFgq5V"
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "def generate_single_case(\n",
    "    pearl_level: str,\n",
    "    trap_type: str,\n",
    "    case_number: int,\n",
    "    max_retries: int = 4,\n",
    "    desired_label: str | None = None,\n",
    ") -> dict:\n",
    "    \"\"\"Generate a single case; returns schema-shaped dict. If desired_label is set, enforce it.\"\"\"\n",
    "    pearl_level = (pearl_level or \"\").strip().upper()\n",
    "    trap_type = canonical_trap_type(trap_type)\n",
    "    desired_label = (desired_label or \"\").strip().upper() if desired_label else None\n",
    "\n",
    "    # For YES/AMBIGUOUS, there is no trap type\n",
    "    if desired_label in {\"YES\", \"AMBIGUOUS\"}:\n",
    "        trap_type = \"NONE\"\n",
    "\n",
    "    allowed = TRAP_TYPES_BY_PEARL.get(pearl_level, [])\n",
    "    if trap_type != \"NONE\" and trap_type not in allowed:\n",
    "        return {\n",
    "            \"id\": f\"T3-BucketLarge-E-1.{case_number}\",\n",
    "            \"case_id\": f\"1.{case_number}\",\n",
    "            \"error\": f\"trap_type '{trap_type}' not allowed for pearl_level '{pearl_level}'. Allowed: {allowed}\"\n",
    "        }\n",
    "\n",
    "    case_id = f\"1.{case_number}\"\n",
    "    trap_guide = TRAP_GUIDES[trap_type]\n",
    "    allowed_subtypes = TRAP_SUBTYPES.get((pearl_level, trap_type), [])\n",
    "\n",
    "    def _call_model(feedback: str | None = None) -> dict:\n",
    "        prompt = generate_case_prompt(\n",
    "            pearl_level=pearl_level,\n",
    "            trap_type=trap_type,\n",
    "            case_number=case_number,\n",
    "            trap_guide=trap_guide,\n",
    "            allowed_subtypes=allowed_subtypes,\n",
    "            desired_label=desired_label,\n",
    "        )\n",
    "        if feedback:\n",
    "            prompt = prompt + \"\\n\\nCORRECTION:\\n\" + feedback\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Output valid JSON only. No markdown. No extra text.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            max_tokens=1200,\n",
    "            temperature=0.35,\n",
    "        )\n",
    "        text = response.choices[0].message.content or \"\"\n",
    "        start = text.find(\"{\")\n",
    "        end = text.rfind(\"}\")\n",
    "        if start == -1 or end == -1 or end <= start:\n",
    "            raise json.JSONDecodeError(\"No JSON object found\", text, 0)\n",
    "        obj = json.loads(text[start:end+1])\n",
    "        return obj\n",
    "\n",
    "    feedback = None\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            obj = _call_model(feedback)\n",
    "\n",
    "            # enforce fixed domain and trap_type\n",
    "            obj[\"domain\"] = \"Daily Life\"\n",
    "            obj[\"trap_type\"] = trap_type\n",
    "\n",
    "            lab = str(obj.get(\"label\", \"\")).strip().upper()\n",
    "            if lab not in {\"YES\", \"NO\", \"AMBIGUOUS\"}:\n",
    "                lab = \"NO\"\n",
    "                obj[\"label\"] = \"NO\"\n",
    "\n",
    "            if lab in {\"YES\", \"AMBIGUOUS\"}:\n",
    "                obj[\"trap_type\"] = \"NONE\"\n",
    "                obj[\"trap_subtype\"] = \"\"\n",
    "\n",
    "            # enforce desired label if requested\n",
    "            if desired_label in {\"YES\", \"NO\", \"AMBIGUOUS\"} and lab != desired_label:\n",
    "                feedback = f'Your previous JSON had label=\"{lab}\". Re-generate with label EXACTLY \"{desired_label}\". Keep trap_type \"{trap_type}\".'\n",
    "                time.sleep(0.6)\n",
    "                continue\n",
    "\n",
    "            return convert_to_final_format(obj, pearl_level, trap_type, case_id)\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            feedback = \"Your previous output was not valid JSON. Output ONLY one valid JSON object.\"\n",
    "            time.sleep(0.8)\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            feedback = f\"Exception occurred: {type(e).__name__}: {e}. Output valid JSON only.\"\n",
    "            time.sleep(0.8)\n",
    "            continue\n",
    "\n",
    "    return {\n",
    "        \"id\": f\"T3-BucketLarge-E-{case_id}\",\n",
    "        \"case_id\": case_id,\n",
    "        \"error\": f\"Failed after retries (desired_label={desired_label})\",\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vhcOeHkgq5V"
   },
   "source": [
    "## Part 1: Test Generation (10 Cases)\n",
    "\n",
    "**Run this first** to verify everything works before generating all 230 cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNTKyfkMgq5W"
   },
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def generate_test_cases(num_cases: int = 10) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Generate a small sanity-check set with explicit YES/NO/AMBIGUOUS labels.\n",
    "    IMPORTANT: YES and AMBIGUOUS must have trap_type = NONE.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Generating {num_cases} test cases...\\n\")\n",
    "\n",
    "    # (Pearl level, trap, desired_label)\n",
    "    case_specs = [\n",
    "        (\"L1\", \"REGRESSION\", \"NO\"),\n",
    "        (\"L1\", \"BASE_RATE\", \"NO\"),\n",
    "        (\"L2\", \"CONFOUNDER_MEDIATOR_ERROR\", \"NO\"),\n",
    "        (\"L2\", \"SELECTION\", \"NO\"),\n",
    "\n",
    "        # YES cases -> trap must be NONE\n",
    "        (\"L1\", \"NONE\", \"YES\"),\n",
    "        (\"L2\", \"NONE\", \"YES\"),\n",
    "\n",
    "        # AMBIGUOUS cases -> trap must be NONE\n",
    "        (\"L1\", \"NONE\", \"AMBIGUOUS\"),\n",
    "        (\"L2\", \"NONE\", \"AMBIGUOUS\"),\n",
    "\n",
    "        # L3 mix\n",
    "        (\"L3\", \"PREEMPTION\", \"NO\"),\n",
    "        (\"L3\", \"NONE\", \"YES\"),\n",
    "    ]\n",
    "\n",
    "    cases = []\n",
    "    for i, (level, trap, desired_label) in enumerate(\n",
    "        tqdm(case_specs[:num_cases], desc=\"Generating test cases\")\n",
    "    ):\n",
    "        case = generate_single_case(\n",
    "            level,\n",
    "            trap,\n",
    "            1000 + i,\n",
    "            desired_label=desired_label\n",
    "        )\n",
    "\n",
    "        if case and \"error\" not in case:\n",
    "            cases.append(case)\n",
    "            cid = case.get(\"case_id\") or case.get(\"id\") or f\"1.{1000+i}\"\n",
    "            print(f\"✓ {cid} [{level} | {desired_label} | trap={case.get('trap',{}).get('type','')}]\")\n",
    "        else:\n",
    "            err = case.get(\"error\", \"\") if isinstance(case, dict) else \"\"\n",
    "            print(f\"✗ Failed to generate case {1000 + i}: {err}\")\n",
    "\n",
    "        time.sleep(0.7)\n",
    "\n",
    "    return cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344,
     "referenced_widgets": [
      "8a9b0cd5753e424fbbb3e37680dad682",
      "c541ede0dfd54b8c8611f68a215f9ade",
      "ba5c33d5a700437bb8ae985ee4cc0c78",
      "7bdd2a7e91554c078e6700f94fd4e6ef",
      "d19f7700bd7743518d1dca6a36a24e15",
      "2faca966c3754a9e871f79a23c66e40a",
      "7d9dae68b71a4226bb797adc1a7dea74",
      "b54a4a65ce53443dadce19d186004247",
      "612b3454bd4646e3a5ea7cacdb4cbd5f",
      "b39ab7d23aed46c6bb02303f98b43e8f",
      "fa8194ff7fd4425193d6c9b33f22eb03"
     ]
    },
    "id": "GzlCYlBWgq5W",
    "outputId": "1ad8cf35-a594-492d-be1e-a90412ee32e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10 test cases...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9b0cd5753e424fbbb3e37680dad682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test cases:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 1.1000: Star Student Slump [L1 - REGRESSION TO MEAN]\n",
      "✓ 1.1001: Lucky Lottery Retailer [L1 - BASE RATE NEGLECT]\n",
      "✓ 1.1002: Coffee Cup Perks [L2 - CONF-MED]\n",
      "✓ 1.1003: Weekend Tutor Trap [L2 - SELECTION]\n",
      "✓ 1.1004: Nightlight Anxiety Trap [L2 - REVERSE]\n",
      "✓ 1.1005: Parking Permit Paradox [L2 - COLLIDER]\n",
      "✓ 1.1006: Streaming & Sleepless Nights [L2 - CONF-MED]\n",
      "✓ 1.1007: Free Coffee Promotion Effect [L3 - COUNTERFACTUAL]\n",
      "✓ 1.1008: Missed Train, Lost Job [L3 - COUNTERFACTUAL]\n",
      "✓ 1.1009: Frequent Library Visits [L2 - SELECTION]\n",
      "\n",
      "============================================================\n",
      "Generated 10 test cases\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS: Generate 10 test cases\n",
    "test_cases = generate_test_cases(10)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Generated {len(test_cases)} test cases\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EqvLnwgCgq5W",
    "outputId": "a43820f2-8e14-4753-ccd5-81135b8adb50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Case:\n",
      "============================================================\n",
      "Title: Star Student Slump\n",
      "Level: Association\n",
      "Trap: REGRESSION TO MEAN\n",
      "\n",
      "Scenario: In the first semester, Jamie earns nearly perfect grades, much higher than most students. When Jamie later receives lower grades in the second semester, classmates say the tougher subjects caused Jamie to suddenly lose their 'gift.'\n",
      "\n",
      "Wise Refusal: A wise AI would point out that Jamie's grades may be regressing to the mean and the drop is expected after an exceptionally strong performance. It's incorrect to assume that only new negative factors are responsible for the change without considering normal variation.\n",
      "\n",
      "Full JSON:\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "annotation": {
        "adjudicated": false,
        "agreement": "ai_generated",
        "num_annotators": 1
       },
       "bucket": "BucketLarge-E",
       "case_id": "1.1000",
       "causal_structure": "Jamie's extremely high first semester grades are partly due to chance, so their later grades naturally return closer to the average regardless of new influences.",
       "claim": "Jamie's high achievement was directly caused by exceptional academic talent, so any drop in grades must be due to new negative influences.",
       "conditional_answers": [],
       "difficulty": "Easy",
       "domain_id": "D1",
       "domain_name": "Daily Life",
       "gold_rationale": "A wise AI would point out that Jamie's grades may be regressing to the mean and the drop is expected after an exceptionally strong performance. It's incorrect to assume that only new negative factors are responsible for the change without considering normal variation.",
       "hidden_structure": {
        "dag_edges": [
         [
          "X",
          "Y"
         ]
        ],
        "notes": "Jamie's extremely high first semester grades are partly due to chance, so their later grades naturally return closer to the average regardless of new influences."
       },
       "hidden_timestamp": {
        "answer": "",
        "question": ""
       },
       "id": "T3-BucketLarge-E-1.1000",
       "is_ambiguous": false,
       "key_insight": "Extreme results usually regress toward the average on subsequent measurements due to natural randomness.",
       "label": "NO",
       "label_name": "FLAWED",
       "pearl_level": "L1",
       "pearl_level_name": "Association",
       "scenario": "In the first semester, Jamie earns nearly perfect grades, much higher than most students. When Jamie later receives lower grades in the second semester, classmates say the tougher subjects caused Jamie to suddenly lose their 'gift.'",
       "source": {
        "generation_date": "2026-01-12",
        "generator": "claude-sonnet-4-20250514",
        "origin": "generated",
        "seed_case_ref": "bucket_E_examples"
       },
       "subdomain": "Education",
       "title": "Star Student Slump",
       "trap": {
        "subtype": "Regression to the Mean",
        "subtype_name": "Regression To The Mean",
        "type": "REGRESSION TO MEAN",
        "type_name": "Regression To Mean"
       },
       "variables": {
        "X": {
         "description": "Jamie's academic performance in the first semester",
         "name": "First semester grades",
         "role": "exposure"
        },
        "Y": {
         "description": "Jamie's academic performance in the second semester",
         "name": "Second semester grades",
         "role": "outcome"
        },
        "Z": [
         {
          "description": "Chance factors and natural fluctuations in performance",
          "name": "Random variation",
          "role": "common_cause"
         }
        ]
       },
       "wise_refusal": "A wise AI would point out that Jamie's grades may be regressing to the mean and the drop is expected after an exceptionally strong performance. It's incorrect to assume that only new negative factors are responsible for the change without considering normal variation."
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View a sample case\n",
    "if test_cases:\n",
    "    print(\"Sample Case:\")\n",
    "    print(\"=\" * 60)\n",
    "    sample = test_cases[0]\n",
    "    print(f\"Title: {sample.get('title')}\")\n",
    "    print(f\"Level: {sample.get('pearl_level_name')}\")\n",
    "    print(f\"Trap: {sample.get('trap', {}).get('type')}\")\n",
    "    print(f\"\\nScenario: {sample.get('scenario')}\")\n",
    "    print(f\"\\nWise Refusal: {sample.get('wise_refusal')}\")\n",
    "    print(\"\\nFull JSON:\")\n",
    "    display(JSON(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71dw4hxOgq5W"
   },
   "outputs": [],
   "source": [
    "# Save test cases\n",
    "test_output = \"t3_test_cases.json\"\n",
    "with open(test_output, 'w') as f:\n",
    "    json.dump({\n",
    "        \"metadata\": {\n",
    "            \"total_cases\": len(test_cases),\n",
    "            \"generation_date\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"model\": \"claude-sonnet-4-20250514\"\n",
    "        },\n",
    "        \"cases\": test_cases\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"✓ Saved to: {test_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtyZzRQ2gq5W"
   },
   "source": [
    "## Part 2: Full Generation (230 Cases)\n",
    "\n",
    "⚠️ **This will take 6-8 hours and cost ~$2-3**\n",
    "\n",
    "Only run this after reviewing the test cases above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8wr_MVy5gq5W"
   },
   "outputs": [],
   "source": [
    "def generate_all_cases(target_total: int = 230) -> List[Dict]:\n",
    "    \"\"\"Generate all cases maintaining distribution\"\"\"\n",
    "\n",
    "    # Calculate distribution\n",
    "    l1_count = int(target_total * 0.11)  # 11%\n",
    "    l2_count = int(target_total * 0.64)  # 64%\n",
    "    l3_count = target_total - l1_count - l2_count\n",
    "\n",
    "    print(f\"Generating {target_total} cases:\")\n",
    "    print(f\"  L1 (Association): {l1_count}\")\n",
    "    print(f\"  L2 (Intervention): {l2_count}\")\n",
    "    print(f\"  L3 (Counterfactual): {l3_count}\")\n",
    "    print()\n",
    "\n",
    "    all_cases = []\n",
    "    case_counter = 50  # Start after existing 45 cases\n",
    "\n",
    "    # Generate L1 cases\n",
    "    print(\"\\n=== Generating L1 (Association) Cases ===\")\n",
    "    l1_trap_types = TRAP_TYPES[\"L1\"]\n",
    "    for i in tqdm(range(l1_count), desc=\"L1 Cases\"):\n",
    "        trap_type = random.choice(l1_trap_types)\n",
    "        case = generate_single_case(\"L1\", trap_type, case_counter)\n",
    "        if \"error\" not in case:\n",
    "            all_cases.append(case)\n",
    "        case_counter += 1\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # Generate L2 cases\n",
    "    print(\"\\n=== Generating L2 (Intervention) Cases ===\")\n",
    "    l2_trap_types = TRAP_TYPES[\"L2\"]\n",
    "    for i in tqdm(range(l2_count), desc=\"L2 Cases\"):\n",
    "        trap_type = random.choice(l2_trap_types)\n",
    "        case = generate_single_case(\"L2\", trap_type, case_counter)\n",
    "        if \"error\" not in case:\n",
    "            all_cases.append(case)\n",
    "        case_counter += 1\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # Generate L3 cases\n",
    "    print(\"\\n=== Generating L3 (Counterfactual) Cases ===\")\n",
    "    for i in tqdm(range(l3_count), desc=\"L3 Cases\"):\n",
    "        case = generate_single_case(\"L3\", \"COUNTERFACTUAL\", case_counter)\n",
    "        if \"error\" not in case:\n",
    "            all_cases.append(case)\n",
    "        case_counter += 1\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    return all_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sy0NPf9zgq5W"
   },
   "outputs": [],
   "source": [
    "# RUN THIS: Generate all 230 cases (takes 6-8 hours!)\n",
    "# Comment out if you don't want to run yet\n",
    "\n",
    "# all_cases = generate_all_cases(target_total=230)\n",
    "\n",
    "# print(f\"\\n{'='*60}\")\n",
    "# print(f\"✓ Successfully generated {len(all_cases)} cases\")\n",
    "# print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pj_i_m3ngq5W"
   },
   "outputs": [],
   "source": [
    "# Save all cases\n",
    "# Uncomment when you've generated all cases\n",
    "\n",
    "# output_file = \"t3_generated_cases_full.json\"\n",
    "# with open(output_file, 'w') as f:\n",
    "#     json.dump({\n",
    "#         \"metadata\": {\n",
    "#             \"total_cases\": len(all_cases),\n",
    "#             \"generation_date\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "#             \"model\": \"claude-sonnet-4-20250514\",\n",
    "#             \"bucket\": \"BucketLarge-E\",\n",
    "#             \"domain\": \"Daily Life & Psychology\"\n",
    "#         },\n",
    "#         \"cases\": all_cases\n",
    "#     }, f, indent=2)\n",
    "\n",
    "# # Print statistics\n",
    "# l1_count = sum(1 for c in all_cases if c.get(\"pearl_level\") == \"L1\")\n",
    "# l2_count = sum(1 for c in all_cases if c.get(\"pearl_level\") == \"L2\")\n",
    "# l3_count = sum(1 for c in all_cases if c.get(\"pearl_level\") == \"L3\")\n",
    "\n",
    "# print(f\"\\nFinal Distribution:\")\n",
    "# print(f\"  L1: {l1_count} ({l1_count/len(all_cases)*100:.1f}%)\")\n",
    "# print(f\"  L2: {l2_count} ({l2_count/len(all_cases)*100:.1f}%)\")\n",
    "# print(f\"  L3: {l3_count} ({l3_count/len(all_cases)*100:.1f}%)\")\n",
    "# print(f\"\\n✓ Saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fi0F2xe4gq5W"
   },
   "source": [
    "## Part 3: Batch Generation with Checkpoints (RECOMMENDED)\n",
    "\n",
    "This version generates cases in batches of 50 and saves progress after each batch.  \n",
    "**Safer than generating all 230 at once!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suwpqvA3gq5W"
   },
   "outputs": [],
   "source": [
    "# Checkpoint file\n",
    "CHECKPOINT_FILE = \"t3_checkpoint.json\"\n",
    "BATCH_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nh9nsNCMgq5W"
   },
   "outputs": [],
   "source": [
    "def load_checkpoint() -> List[Dict]:\n",
    "    \"\"\"Load previously generated cases\"\"\"\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        with open(CHECKPOINT_FILE, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            return data.get(\"cases\", [])\n",
    "    return []\n",
    "\n",
    "def save_checkpoint(cases: List[Dict]):\n",
    "    \"\"\"Save progress\"\"\"\n",
    "    with open(CHECKPOINT_FILE, 'w') as f:\n",
    "        json.dump({\n",
    "            \"metadata\": {\n",
    "                \"total_cases\": len(cases),\n",
    "                \"last_updated\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            },\n",
    "            \"cases\": cases\n",
    "        }, f, indent=2)\n",
    "    print(f\"✓ Checkpoint saved: {len(cases)} total cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oR07mK2Sgq5W"
   },
   "outputs": [],
   "source": [
    "def generate_batch(pearl_level: str, trap_types: List[str], start_number: int, count: int) -> List[Dict]:\n",
    "    \"\"\"Generate a batch of cases\"\"\"\n",
    "\n",
    "    batch = []\n",
    "    for i in range(count):\n",
    "        trap_type = random.choice(trap_types)\n",
    "        case_number = start_number + i\n",
    "\n",
    "        case = generate_single_case(pearl_level, trap_type, case_number)\n",
    "        if case and \"error\" not in case:\n",
    "            batch.append(case)\n",
    "            print(f\"  ✓ {case['case_id']}: {case.get('title', 'Untitled')}\")\n",
    "\n",
    "        time.sleep(0.7)\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVh3hASagq5W"
   },
   "outputs": [],
   "source": [
    "# Check existing progress\n",
    "existing_cases = load_checkpoint()\n",
    "print(f\"Found {len(existing_cases)} existing cases in checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_1ufiFUgq5W"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "\n",
    "def batch_generate_all(\n",
    "    target_total: int = 230,\n",
    "    out_path: str = \"t3_bucketlarge_e.jsonl\",\n",
    "    seed: int = 13,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generate target_total examples with YES/NO/AMBIGUOUS in a 1:1:1 ratio.\n",
    "    Writes JSONL.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Build desired label schedule: equal counts as close as possible\n",
    "    base = target_total // 3\n",
    "    rem = target_total % 3\n",
    "    labels = ([\"YES\"] * base) + ([\"NO\"] * base) + ([\"AMBIGUOUS\"] * base)\n",
    "    # distribute remainder\n",
    "    if rem >= 1: labels.append(\"YES\")\n",
    "    if rem >= 2: labels.append(\"NO\")\n",
    "    random.shuffle(labels)\n",
    "\n",
    "    # choose pearl levels uniformly\n",
    "    pearl_levels = [\"L1\", \"L2\", \"L3\"]\n",
    "\n",
    "    all_cases = []\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for idx, desired_label in enumerate(tqdm(labels, desc=\"Generating cases\")):\n",
    "            case_number = idx + 1\n",
    "\n",
    "            level = random.choice(pearl_levels)\n",
    "            if desired_label in {\"YES\", \"AMBIGUOUS\"}:\n",
    "                trap = \"NONE\"\n",
    "            else:\n",
    "                trap = random.choice(TRAP_TYPES_BY_PEARL[level])\n",
    "\n",
    "            case = generate_single_case(level, trap, case_number, desired_label=desired_label)\n",
    "\n",
    "            if isinstance(case, dict) and \"error\" not in case:\n",
    "                all_cases.append(case)\n",
    "                f.write(json.dumps(case, ensure_ascii=False) + \"\\n\")\n",
    "            else:\n",
    "                # still write error rows for debugging? comment out if you prefer\n",
    "                err = case.get(\"error\") if isinstance(case, dict) else \"Unknown error\"\n",
    "                f.write(json.dumps({\"case_id\": f\"1.{case_number}\", \"error\": err}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "            time.sleep(0.4)\n",
    "\n",
    "    print(f\"\\nWrote {len(all_cases)} valid cases to {out_path}\")\n",
    "    # quick ratio report\n",
    "    counts = {\"YES\": 0, \"NO\": 0, \"AMBIGUOUS\": 0}\n",
    "    for c in all_cases:\n",
    "        lab = str(c.get(\"label\",\"\")).upper()\n",
    "        if lab in counts: counts[lab] += 1\n",
    "    print(\"Label counts:\", counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "By3juz_Ogq5W"
   },
   "outputs": [],
   "source": [
    "# RUN THIS: Generate all cases in batches (RECOMMENDED METHOD)\n",
    "# This will save progress after every 50 cases\n",
    "\n",
    "final_cases = batch_generate_all(target_total=230)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"✓ COMPLETE: {len(final_cases)} total cases\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "me_THQ2Ogq5W"
   },
   "outputs": [],
   "source": [
    "# Save final output\n",
    "final_output = \"t3_generated_cases_final.json\"\n",
    "with open(final_output, 'w') as f:\n",
    "    json.dump({\n",
    "        \"metadata\": {\n",
    "            \"total_cases\": len(final_cases),\n",
    "            \"generation_date\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"model\": \"claude-sonnet-4-20250514\",\n",
    "            \"bucket\": \"BucketLarge-E\",\n",
    "            \"domain\": \"Daily Life & Psychology\"\n",
    "        },\n",
    "        \"cases\": final_cases\n",
    "    }, f, indent=2)\n",
    "\n",
    "# Print final statistics\n",
    "l1_final = sum(1 for c in final_cases if c.get(\"pearl_level\") == \"L1\")\n",
    "l2_final = sum(1 for c in final_cases if c.get(\"pearl_level\") == \"L2\")\n",
    "l3_final = sum(1 for c in final_cases if c.get(\"pearl_level\") == \"L3\")\n",
    "\n",
    "print(f\"\\nFinal Distribution:\")\n",
    "print(f\"  L1: {l1_final} ({l1_final/len(final_cases)*100:.1f}%)\")\n",
    "print(f\"  L2: {l2_final} ({l2_final/len(final_cases)*100:.1f}%)\")\n",
    "print(f\"  L3: {l3_final} ({l3_final/len(final_cases)*100:.1f}%)\")\n",
    "print(f\"\\n✓ Saved to: {final_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rn12g5J1gq5X"
   },
   "source": [
    "## Analysis & Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LlYAlsHZgq5X"
   },
   "outputs": [],
   "source": [
    "# Load generated cases for analysis\n",
    "# Change filename as needed\n",
    "with open('t3_test_cases.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    cases_to_analyze = data['cases']\n",
    "\n",
    "print(f\"Analyzing {len(cases_to_analyze)} cases...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Iye7EtRgq5X"
   },
   "outputs": [],
   "source": [
    "# Distribution analysis\n",
    "from collections import Counter\n",
    "\n",
    "pearl_levels = Counter(c.get('pearl_level') for c in cases_to_analyze)\n",
    "trap_types = Counter(c.get('trap', {}).get('type') for c in cases_to_analyze)\n",
    "difficulties = Counter(c.get('difficulty') for c in cases_to_analyze)\n",
    "subdomains = Counter(c.get('subdomain') for c in cases_to_analyze)\n",
    "\n",
    "print(\"Pearl Level Distribution:\")\n",
    "for level, count in pearl_levels.most_common():\n",
    "    print(f\"  {level}: {count} ({count/len(cases_to_analyze)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nTrap Type Distribution:\")\n",
    "for trap, count in trap_types.most_common():\n",
    "    print(f\"  {trap}: {count}\")\n",
    "\n",
    "print(\"\\nDifficulty Distribution:\")\n",
    "for diff, count in difficulties.most_common():\n",
    "    print(f\"  {diff}: {count}\")\n",
    "\n",
    "print(\"\\nTop Subdomains:\")\n",
    "for subdomain, count in subdomains.most_common(10):\n",
    "    print(f\"  {subdomain}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lMCnxYPgq5X"
   },
   "outputs": [],
   "source": [
    "# Sample cases from each level\n",
    "print(\"Sample L1 Case:\")\n",
    "l1_cases = [c for c in cases_to_analyze if c.get('pearl_level') == 'L1']\n",
    "if l1_cases:\n",
    "    sample = l1_cases[0]\n",
    "    print(f\"Title: {sample.get('title')}\")\n",
    "    print(f\"Scenario: {sample.get('scenario')}\")\n",
    "    print(f\"Trap: {sample.get('trap', {}).get('type')}\")\n",
    "    print(f\"Wise Refusal: {sample.get('wise_refusal')}\\n\")\n",
    "\n",
    "print(\"\\nSample L2 Case:\")\n",
    "l2_cases = [c for c in cases_to_analyze if c.get('pearl_level') == 'L2']\n",
    "if l2_cases:\n",
    "    sample = l2_cases[0]\n",
    "    print(f\"Title: {sample.get('title')}\")\n",
    "    print(f\"Scenario: {sample.get('scenario')}\")\n",
    "    print(f\"Trap: {sample.get('trap', {}).get('type')}\")\n",
    "    print(f\"Wise Refusal: {sample.get('wise_refusal')}\\n\")\n",
    "\n",
    "print(\"\\nSample L3 Case:\")\n",
    "l3_cases = [c for c in cases_to_analyze if c.get('pearl_level') == 'L3']\n",
    "if l3_cases:\n",
    "    sample = l3_cases[0]\n",
    "    print(f\"Title: {sample.get('title')}\")\n",
    "    print(f\"Scenario: {sample.get('scenario')}\")\n",
    "    print(f\"Wise Refusal: {sample.get('wise_refusal')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wd1YQOt0gq5X"
   },
   "source": [
    "## Summary\n",
    "\n",
    "You now have:\n",
    "1. ✅ Test cases (10) to verify quality\n",
    "2. ✅ Full generation capability (230 cases)\n",
    "3. ✅ Batch generation with checkpoints (safest method)\n",
    "4. ✅ Analysis tools\n",
    "\n",
    "**Next Steps:**\n",
    "1. Review test cases for quality\n",
    "2. Run batch generation (recommended)\n",
    "3. Analyze distribution\n",
    "4. Edit any low-quality cases\n",
    "5. Write your quality analysis report\n",
    "6. Submit!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2faca966c3754a9e871f79a23c66e40a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "612b3454bd4646e3a5ea7cacdb4cbd5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7bdd2a7e91554c078e6700f94fd4e6ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b39ab7d23aed46c6bb02303f98b43e8f",
      "placeholder": "​",
      "style": "IPY_MODEL_fa8194ff7fd4425193d6c9b33f22eb03",
      "value": " 10/10 [00:36&lt;00:00,  3.61s/it]"
     }
    },
    "7d9dae68b71a4226bb797adc1a7dea74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a9b0cd5753e424fbbb3e37680dad682": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c541ede0dfd54b8c8611f68a215f9ade",
       "IPY_MODEL_ba5c33d5a700437bb8ae985ee4cc0c78",
       "IPY_MODEL_7bdd2a7e91554c078e6700f94fd4e6ef"
      ],
      "layout": "IPY_MODEL_d19f7700bd7743518d1dca6a36a24e15"
     }
    },
    "b39ab7d23aed46c6bb02303f98b43e8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b54a4a65ce53443dadce19d186004247": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba5c33d5a700437bb8ae985ee4cc0c78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b54a4a65ce53443dadce19d186004247",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_612b3454bd4646e3a5ea7cacdb4cbd5f",
      "value": 10
     }
    },
    "c541ede0dfd54b8c8611f68a215f9ade": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2faca966c3754a9e871f79a23c66e40a",
      "placeholder": "​",
      "style": "IPY_MODEL_7d9dae68b71a4226bb797adc1a7dea74",
      "value": "Generating test cases: 100%"
     }
    },
    "d19f7700bd7743518d1dca6a36a24e15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa8194ff7fd4425193d6c9b33f22eb03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
